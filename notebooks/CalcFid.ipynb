{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "j5GhYriyCNBT",
    "outputId": "71f74033-8c04-436b-e2ad-5e61fe154b1b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
     ]
    }
   ],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xup_gYOvCTlK"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "# from kaggle_datasets import KaggleDatasets\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "from keras.applications.inception_v3 import preprocess_input\n",
    "from scipy.linalg import sqrtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Iwm1ctZtCaLp",
    "outputId": "e8d7469a-e93d-48bf-fbe1-bfe551cee189"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  Building wheel for tensorflow-examples (setup.py) ... \u001b[?25l\u001b[?25hdone\n"
     ]
    }
   ],
   "source": [
    "!pip install -q git+https://github.com/tensorflow/examples.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gOmfydcSCb09"
   },
   "outputs": [],
   "source": [
    "from tensorflow_examples.models.pix2pix import pix2pix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "zIZ-EmiLCeTt",
    "outputId": "5b51ed14-a4b7-4450-9e54-6eaf6e1e4b2b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Connection failed.\n",
      "Number of replicas: 1\n",
      "2.3.0\n"
     ]
    }
   ],
   "source": [
    "# Attempting to connect to a TPU cluster and configurating it\n",
    "try:\n",
    "    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n",
    "    print('Device:', tpu.master())\n",
    "    tf.config.experimental_connect_to_cluster(tpu)\n",
    "    tf.tpu.experimental.initialize_tpu_system(tpu)\n",
    "    strategy = tf.distribute.TPUStrategy(tpu)\n",
    "    # strategy = tf.distribute.experimental.TPUStrategy(tpu)\n",
    "\n",
    "except:\n",
    "    print(\"Connection failed.\")\n",
    "    strategy = tf.distribute.get_strategy()\n",
    "  \n",
    "print('Number of replicas:', strategy.num_replicas_in_sync)\n",
    "\n",
    "AUTOTUNE = tf.data.experimental.AUTOTUNE\n",
    "    \n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "0dX9HpbvChbx"
   },
   "outputs": [],
   "source": [
    "# Setting up the paths to the .tfrec files from the dataset\n",
    "# MONET_PATH = \"./dataset/monet/\"\n",
    "# PHOTO_PATH = \"./dataset/photo/\"\n",
    "\n",
    "MONET_TRAIN_PATH = \"/content/drive/Shared drives/Equipe Rocket/8_Sem/Aplic AM/Dataset/alt-monet-tfrecord/train/\"\n",
    "MONET_TEST_PATH = \"/content/drive/Shared drives/Equipe Rocket/8_Sem/Aplic AM/Dataset/alt-monet-tfrecord/test/\"\n",
    "# MONET_PATH = \"/content/drive/Shared drives/Equipe Rocket/8_Sem/Aplic AM/Dataset/monet_tfrec/\"\n",
    "PHOTO_TRAIN_PATH = \"/content/drive/Shared drives/Equipe Rocket/8_Sem/Aplic AM/Dataset/alt-photos-tfrecord/train/\"\n",
    "PHOTO_TEST_PATH = \"/content/drive/Shared drives/Equipe Rocket/8_Sem/Aplic AM/Dataset/alt-photos-tfrecord/test/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "47TWDunLCj4n",
    "outputId": "b614c2f2-3b21-41e5-b5a0-1a180a3fbf58"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Monet train TFRecord Files: 4\n",
      "Monet TEST TFRecord Files: 1\n",
      "Photos train TFRecord Files: 4\n",
      "Photos test TFRecord Files: 1\n"
     ]
    }
   ],
   "source": [
    "# Loading the dataset filenames to use them in our models later on\n",
    "MONET_TRAIN_FILENAMES = tf.io.gfile.glob(str(MONET_TRAIN_PATH + \"*.tfrec\"))\n",
    "print('Monet train TFRecord Files:', len(MONET_TRAIN_FILENAMES))\n",
    "MONET_TEST_FILENAMES = tf.io.gfile.glob(str(MONET_TEST_PATH + \"*.tfrec\"))\n",
    "print('Monet TEST TFRecord Files:', len(MONET_TEST_FILENAMES))\n",
    "\n",
    "PHOTO_TRAIN_FILENAMES = tf.io.gfile.glob(str(PHOTO_TRAIN_PATH + \"*.tfrec\"))\n",
    "print('Photos train TFRecord Files:', len(PHOTO_TRAIN_FILENAMES))\n",
    "PHOTO_TEST_FILENAMES = tf.io.gfile.glob(str(PHOTO_TEST_PATH + \"*.tfrec\"))\n",
    "print('Photos test TFRecord Files:', len(PHOTO_TEST_FILENAMES))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "2rfwF9RbCmZZ"
   },
   "outputs": [],
   "source": [
    "# Auxiliary functions to manage the tfrecords\n",
    "IMAGE_SIZE = [256, 256]\n",
    "\n",
    "# Adjusting the image dimensions and scale\n",
    "def decode_image(image):\n",
    "    image = tf.image.decode_jpeg(image, channels=3)\n",
    "    image = (tf.cast(image, tf.float32) / 127.5) - 1\n",
    "    image = tf.reshape(image, [*IMAGE_SIZE, 3])\n",
    "    return image\n",
    "\n",
    "# Parsing each element of the dataset\n",
    "def read_tfrecord(example):\n",
    "    tfrecord_format = {\n",
    "        # \"image_name\": tf.io.FixedLenFeature([], tf.string),\n",
    "        \"image\": tf.io.FixedLenFeature([], tf.string),\n",
    "        # \"target\": tf.io.FixedLenFeature([], tf.string)\n",
    "    }\n",
    "    example = tf.io.parse_single_example(example, tfrecord_format)\n",
    "    image = decode_image(example['image'])\n",
    "    return image\n",
    "\n",
    "# Reads the tfrecords and parses them using the read_tfrecord function\n",
    "def load_dataset(filenames, labeled=True, ordered=False):\n",
    "    dataset = tf.data.TFRecordDataset(filenames)\n",
    "    dataset = dataset.map(read_tfrecord)#, num_parallel_calls=AUTOTUNE)\n",
    "    return dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ciby3iIJComS"
   },
   "outputs": [],
   "source": [
    "monet_train_ds = load_dataset(MONET_TRAIN_FILENAMES, labeled=True).batch(1)\n",
    "monet_test_ds = load_dataset(MONET_TEST_FILENAMES, labeled=True).batch(1)\n",
    "\n",
    "photo_train_ds = load_dataset(PHOTO_TRAIN_FILENAMES, labeled=True).batch(1)\n",
    "photo_test_ds = load_dataset(PHOTO_TEST_FILENAMES, labeled=True).batch(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "P97Skv7UCyCi"
   },
   "outputs": [],
   "source": [
    "LAMBDA = 10\n",
    "loss_obj = tf.keras.losses.BinaryCrossentropy(from_logits=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KazYboUBC2Ru"
   },
   "outputs": [],
   "source": [
    "# Discriminator loss\n",
    "def discriminator_loss(real, generated):\n",
    "    # Compares the real image with a matrix of ones, which is the ideal result\n",
    "    real_loss = loss_obj(tf.ones_like(real), real)\n",
    "\n",
    "    # Compares the generated image with a matrix of zeros, which is the ideal result \n",
    "    generated_loss = loss_obj(tf.zeros_like(generated), generated)\n",
    "\n",
    "    total_disc_loss = real_loss + generated_loss\n",
    "\n",
    "    return total_disc_loss * 0.5\n",
    "  \n",
    "# Generator loss\n",
    "def generator_loss(generated):\n",
    "    # Compares the generated image with a matrix of ones.\n",
    "    # The goal is to have a generated image as close to a real image as possible, i.e., close to a matrix of ones.\n",
    "    return loss_obj(tf.ones_like(generated), generated)\n",
    "\n",
    "# Cycle consistency loss\n",
    "def calc_cycle_loss(real_image, cycled_image):\n",
    "    # Mean absolute error between the real image and the cycled image (generated back to the original domain)\n",
    "    # Example:\n",
    "    # real_image = X\n",
    "    # cycled image = F(G(X)) = X_hat ~ X\n",
    "    loss1 = tf.reduce_mean(tf.abs(real_image - cycled_image))\n",
    "\n",
    "    return LAMBDA * loss1\n",
    "  \n",
    "# Identity loss\n",
    "def identity_loss(real_image, same_image):\n",
    "    # Mean absolute error between an image and its generator (i.e. a horse image with a horse image generator)\n",
    "    loss = tf.reduce_mean(tf.abs(real_image - same_image))\n",
    "    return LAMBDA * 0.5 * loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zt_4jRnNC9kN"
   },
   "outputs": [],
   "source": [
    "class CycleGan(keras.Model):\n",
    "    def __init__(\n",
    "        self,\n",
    "        monet_generator,\n",
    "        photo_generator,\n",
    "        monet_discriminator,\n",
    "        photo_discriminator,\n",
    "    ):\n",
    "        super(CycleGan, self).__init__()\n",
    "        self.m_gen = monet_generator\n",
    "        self.p_gen = photo_generator\n",
    "        self.m_disc = monet_discriminator\n",
    "        self.p_disc = photo_discriminator\n",
    "        \n",
    "    def compile(\n",
    "        self,\n",
    "        m_gen_optimizer,\n",
    "        p_gen_optimizer,\n",
    "        m_disc_optimizer,\n",
    "        p_disc_optimizer,\n",
    "        gen_loss_fn,\n",
    "        disc_loss_fn,\n",
    "        cycle_loss_fn,\n",
    "        identity_loss_fn\n",
    "    ):\n",
    "        super(CycleGan, self).compile()\n",
    "        self.m_gen_optimizer = m_gen_optimizer\n",
    "        self.p_gen_optimizer = p_gen_optimizer\n",
    "        self.m_disc_optimizer = m_disc_optimizer\n",
    "        self.p_disc_optimizer = p_disc_optimizer\n",
    "        self.gen_loss_fn = gen_loss_fn\n",
    "        self.disc_loss_fn = disc_loss_fn\n",
    "        self.cycle_loss_fn = cycle_loss_fn\n",
    "        self.identity_loss_fn = identity_loss_fn\n",
    "        \n",
    "    def train_step(self, batch_data):\n",
    "        real_monet, real_photo = batch_data\n",
    "        \n",
    "        with tf.GradientTape(persistent=True) as tape:\n",
    "            # Generator G translates X -> Y\n",
    "            # Generator F translates Y -> X.\n",
    "\n",
    "            fake_monet = self.m_gen(real_photo, training=True)\n",
    "            cycled_photo = self.p_gen(fake_monet, training=True)\n",
    "\n",
    "            fake_photo = self.p_gen(real_monet, training=True)\n",
    "            cycled_monet = self.m_gen(fake_photo, training=True)\n",
    "\n",
    "            # same_x and same_y are used for identity loss.\n",
    "            same_monet = self.m_gen(real_monet, training=True)\n",
    "            same_photo = self.p_gen(real_photo, training=True)\n",
    "\n",
    "            # discriminator used to check, inputing real images\n",
    "            disc_real_monet = self.m_disc(real_monet, training=True)\n",
    "            disc_real_photo = self.p_disc(real_photo, training=True)\n",
    "\n",
    "            # discriminator used to check, inputing fake images\n",
    "            disc_fake_monet = self.m_disc(fake_monet, training=True)\n",
    "            disc_fake_photo = self.p_disc(fake_photo, training=True)\n",
    "\n",
    "            # evaluates generator loss\n",
    "            monet_gen_loss = self.gen_loss_fn(disc_fake_monet)\n",
    "            photo_gen_loss = self.gen_loss_fn(disc_fake_photo)\n",
    "\n",
    "            # evaluates total cycle consistency loss\n",
    "            total_cycle_loss = self.cycle_loss_fn(real_monet, cycled_monet) + self.cycle_loss_fn(real_photo, cycled_photo)\n",
    "\n",
    "            # evaluates total generator loss\n",
    "            total_monet_gen_loss = monet_gen_loss + total_cycle_loss + self.identity_loss_fn(real_monet, same_monet)\n",
    "            total_photo_gen_loss = photo_gen_loss + total_cycle_loss + self.identity_loss_fn(real_photo, same_photo)\n",
    "\n",
    "            # evaluates discriminator loss\n",
    "            monet_disc_loss = self.disc_loss_fn(disc_real_monet, disc_fake_monet)\n",
    "            photo_disc_loss = self.disc_loss_fn(disc_real_photo, disc_fake_photo)\n",
    "\n",
    "        # Calculate the gradients for generator and discriminator\n",
    "        monet_generator_gradients = tape.gradient(total_monet_gen_loss, self.m_gen.trainable_variables)\n",
    "        photo_generator_gradients = tape.gradient(total_photo_gen_loss, self.p_gen.trainable_variables)\n",
    "\n",
    "        monet_discriminator_gradients = tape.gradient(monet_disc_loss, self.m_disc.trainable_variables)\n",
    "        photo_discriminator_gradients = tape.gradient(photo_disc_loss, self.p_disc.trainable_variables)\n",
    "\n",
    "        # Apply the gradients to the optimizer\n",
    "        self.m_gen_optimizer.apply_gradients(zip(monet_generator_gradients, self.m_gen.trainable_variables))\n",
    "        self.p_gen_optimizer.apply_gradients(zip(photo_generator_gradients, self.p_gen.trainable_variables))\n",
    "        self.m_disc_optimizer.apply_gradients(zip(monet_discriminator_gradients, self.m_disc.trainable_variables))\n",
    "        self.p_disc_optimizer.apply_gradients(zip(photo_discriminator_gradients, self.p_disc.trainable_variables))\n",
    "        \n",
    "        return {\n",
    "            \"monet_gen_loss\": total_monet_gen_loss,\n",
    "            \"photo_gen_loss\": total_photo_gen_loss,\n",
    "            \"monet_disc_loss\": monet_disc_loss,\n",
    "            \"photo_disc_loss\": photo_disc_loss\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZYUfwAPiDBi1"
   },
   "outputs": [],
   "source": [
    "# Creating the generators and discriminators for the CycleGAN\n",
    "\n",
    "OUTPUT_CHANNELS = 3 # RGB channels\n",
    "\n",
    "generator_g = pix2pix.unet_generator(OUTPUT_CHANNELS, norm_type='instancenorm') # X -> Y\n",
    "generator_f = pix2pix.unet_generator(OUTPUT_CHANNELS, norm_type='instancenorm') # Y -> X\n",
    "\n",
    "discriminator_x = pix2pix.discriminator(norm_type='instancenorm', target=False) # Dx\n",
    "discriminator_y = pix2pix.discriminator(norm_type='instancenorm', target=False) # Dy\n",
    "\n",
    "# Optimizers\n",
    "generator_g_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "generator_f_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "\n",
    "discriminator_x_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)\n",
    "discriminator_y_optimizer = tf.keras.optimizers.Adam(2e-4, beta_1=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ftzRmfPXDEDb"
   },
   "outputs": [],
   "source": [
    "with strategy.scope():\n",
    "    \n",
    "    # monet_generator, photo_generator, monet_discriminator, photo_discriminator\n",
    "    cycle_gan_model = CycleGan(\n",
    "        generator_g, generator_f, discriminator_x, discriminator_y\n",
    "    )\n",
    "\n",
    "    cycle_gan_model.compile(\n",
    "        m_gen_optimizer = generator_g_optimizer,\n",
    "        p_gen_optimizer = generator_f_optimizer,\n",
    "        m_disc_optimizer = discriminator_x_optimizer,\n",
    "        p_disc_optimizer = discriminator_y_optimizer,\n",
    "        gen_loss_fn = generator_loss,\n",
    "        disc_loss_fn = discriminator_loss,\n",
    "        cycle_loss_fn = calc_cycle_loss,\n",
    "        identity_loss_fn = identity_loss\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "4NTnQM9JDgdp"
   },
   "outputs": [],
   "source": [
    "import gc\n",
    "\n",
    "model_inception = InceptionV3(include_top=False, pooling='avg', input_shape= (256,256, 3))\n",
    "\n",
    "def calculate_fid_precalculated_stats(model, mu_real, cov_real, images_gen):\n",
    "  act_gen = model.predict(images_gen)\n",
    "\n",
    " \n",
    "  del images_gen\n",
    "  gc.collect()\n",
    "\n",
    "  mu_gen, cov_gen = act_gen.mean(axis=0), np.cov(act_gen, rowvar = False)\n",
    "  \n",
    "  ssdiff = np.sum((mu_real - mu_gen)**2.0)\n",
    "  covmean = sqrtm(cov_real.dot(cov_gen))\n",
    "  if np.iscomplexobj(covmean):\n",
    "    covmean = covmean.real\n",
    "   \n",
    "  fid = ssdiff + np.trace(cov_real + cov_gen - 2.0 * covmean)\n",
    "  return fid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "id": "6sOSuqp3DrQd",
    "outputId": "cf3214f6-5a4f-447f-d15b-6025518b3c85"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1193, 256, 256, 3)"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "monet_ds = list(monet_test_ds.take(-1)) + list(monet_train_ds.take(-1))\n",
    "monet_real = np.array([(img[0] * 127.5 + 127.5).numpy().astype(np.float32) for img in monet_ds])\n",
    "display(monet_real.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "LKCW6Cp2FEe2"
   },
   "outputs": [],
   "source": [
    "monet_real = preprocess_input(monet_real)\n",
    "act_real = model_inception.predict(monet_real)\n",
    "mu_real, cov_real = act_real.mean(axis=0), np.cov(act_real, rowvar = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "z4-vCVCDDGru",
    "outputId": "68bb09f4-77d8-426e-a18d-dcdc8044f969"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo existe:  True\n",
      "Successfully loaded the model 21\n",
      "Fid 77.58551123790514 calculado para 21\n",
      "Arquivo existe:  True\n",
      "Successfully loaded the model 31\n",
      "Fid 73.39263951408883 calculado para 31\n",
      "Arquivo existe:  True\n",
      "Successfully loaded the model 41\n",
      "Fid 73.42120635529338 calculado para 41\n",
      "Arquivo existe:  True\n",
      "Successfully loaded the model 51\n",
      "Fid 74.58160206903887 calculado para 51\n",
      "Arquivo existe:  True\n",
      "Successfully loaded the model 61\n",
      "Fid 70.23957367814737 calculado para 61\n",
      "Arquivo existe:  True\n",
      "Successfully loaded the model 71\n",
      "Fid 71.38538507926017 calculado para 71\n",
      "Arquivo existe:  True\n",
      "Successfully loaded the model 81\n",
      "Fid 73.03217503427533 calculado para 81\n",
      "Arquivo existe:  True\n",
      "Successfully loaded the model 91\n",
      "Fid 73.20088464776667 calculado para 91\n",
      "Arquivo existe:  True\n",
      "Successfully loaded the model 101\n",
      "Fid 72.45309506646394 calculado para 101\n"
     ]
    }
   ],
   "source": [
    "import os.path\n",
    "import gc\n",
    "\n",
    "photo_ds = list(photo_test_ds.take(-1)) + list(photo_train_ds.take(-1))\n",
    "fids = []\n",
    "\n",
    "for i in np.arange(21, 111, 10):\n",
    "  checkpoint_path = \"/content/drive/Shared drives/Equipe Rocket/8_Sem/Aplic AM/checkpoints/\" + str(i) + \"-120split_trainig.h5\" \n",
    "  print('Arquivo existe: ', os.path.exists(checkpoint_path))\n",
    "\n",
    "  try:\n",
    "      cycle_gan_model.built = True\n",
    "      cycle_gan_model.load_weights(filepath=checkpoint_path)\n",
    "      print(\"Successfully loaded the model \" + str(i))\n",
    "\n",
    "  except:\n",
    "      print(\"There is no checkpoint to load\")\n",
    "\n",
    "  pred = []  \n",
    "  for img in photo_ds:\n",
    "    img_pred = generator_g(img, training = False)[0].numpy()\n",
    "    img_pred = (img_pred * 127.5 + 127.5).astype(np.float32)\n",
    "    pred.append(img_pred)\n",
    "\n",
    "  monet_gen = np.array([img for img in pred])\n",
    "  monet_gen = preprocess_input(monet_gen)\n",
    "  fid_i = calculate_fid_precalculated_stats(model_inception, mu_real, cov_real, monet_gen)\n",
    "\n",
    "  fids.append([i, fid_i])\n",
    "  print(\"Fid \" + str(fid_i) + \" calculado para \" + str(i))\n",
    "\n",
    "  del pred\n",
    "  del monet_gen\n",
    "  gc.collect()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yVLFfAruM6sk",
    "outputId": "660826dc-a49e-4a6f-c3ba-b89abaf73a31"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo existe:  True\n",
      "Successfully loaded the model\n",
      "[[120, 72.45314438930383]]\n"
     ]
    }
   ],
   "source": [
    "# Fid 4297.421584347764 calculado para 21\n",
    "# Fid 4690.8566464837695 calculado para 31\n",
    "# Fid 7343.937043087424 calculado para 41\n",
    "checkpoint_path = \"/content/drive/Shared drives/Equipe Rocket/8_Sem/Aplic AM/checkpoints/120split_trainig.h5\" \n",
    "print('Arquivo existe: ', os.path.exists(checkpoint_path))\n",
    "\n",
    "try:\n",
    "  cycle_gan_model.built = True\n",
    "  cycle_gan_model.load_weights(filepath=checkpoint_path)\n",
    "  print(\"Successfully loaded the model\")\n",
    "\n",
    "except:\n",
    "  print(\"There is no checkpoint to load\")\n",
    "\n",
    "pred = []  \n",
    "for img in photo_ds:\n",
    "  img_pred = generator_g(img, training = False)[0].numpy()\n",
    "  img_pred = (img_pred * 127.5 + 127.5).astype(np.float32)\n",
    "  pred.append(img_pred)\n",
    "\n",
    "monet_gen = np.array([img for img in pred])\n",
    "monet_gen = preprocess_input(monet_gen)\n",
    "fid_i = calculate_fid_precalculated_stats(model_inception, mu_real, cov_real, monet_gen)\n",
    "\n",
    "fids.append([120, fid_i])\n",
    "\n",
    "print(fids)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FVSMSYeZ1W1e"
   },
   "source": [
    "# 3166 fotos não vistas no treinamento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YHIghKO9XfVA",
    "outputId": "f996bb3c-9e11-4553-ebd5-a7ce319aec5e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3166, 256, 256, 3)\n"
     ]
    }
   ],
   "source": [
    "# PHOTO_TRAIN_PATH = \"/content/drive/Shared drives/Equipe Rocket/8_Sem/Aplic AM/Dataset/alt-photos-tfrecord/train/\"\n",
    "# PHOTO_TEST_PATH = \"/content/drive/Shared drives/Equipe Rocket/8_Sem/Aplic AM/Dataset/alt-photos-tfrecord/test/\"\n",
    "\n",
    "# PHOTO_TRAIN_FILENAMES = tf.io.gfile.glob(str(PHOTO_TRAIN_PATH + \"*.tfrec\"))\n",
    "# print('Photos train TFRecord Files:', len(PHOTO_TRAIN_FILENAMES))\n",
    "# PHOTO_TEST_FILENAMES = tf.io.gfile.glob(str(PHOTO_TEST_PATH + \"*.tfrec\"))\n",
    "# print('Photos test TFRecord Files:', len(PHOTO_TEST_FILENAMES))\n",
    "\n",
    "# photo_train_ds = load_dataset(PHOTO_TRAIN_FILENAMES, labeled=True).batch(1)\n",
    "# photo_test_ds = load_dataset(PHOTO_TEST_FILENAMES, labeled=True).batch(1)\n",
    "import gc\n",
    "\n",
    "del monet_ds\n",
    "del monet_real\n",
    "del act_real\n",
    "gc.collect()\n",
    "\n",
    "PHOTO_PATH = \"/content/drive/Shared drives/Equipe Rocket/8_Sem/Aplic AM/Dataset/photo_tfrec/photo_fid/\"\n",
    "PHOTO_FILENAMES = tf.io.gfile.glob(str(PHOTO_PATH + \"*.tfrec\"))\n",
    "photo_ds = load_dataset(PHOTO_FILENAMES, labeled=True).batch(1)\n",
    "\n",
    "photo_ds = list(photo_ds)\n",
    "photo_real = np.array([(img[0] * 127.5 + 127.5).numpy().astype(np.float32) for img in photo_ds])\n",
    "print(photo_real.shape)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "EY-CQsajc8Ro",
    "outputId": "3ba64538-ee32-4763-cc52-9ed7b5a2f5df"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo existe:  True\n",
      "Successfully loaded the model 21\n",
      "Fid 77.10029908511594 calculado para 21\n",
      "Arquivo existe:  True\n",
      "Successfully loaded the model 31\n",
      "Fid 72.2697242132921 calculado para 31\n",
      "Arquivo existe:  True\n",
      "Successfully loaded the model 41\n",
      "Fid 73.18617094437968 calculado para 41\n",
      "Arquivo existe:  True\n",
      "Successfully loaded the model 51\n",
      "Fid 72.41483427190339 calculado para 51\n",
      "Arquivo existe:  True\n",
      "Successfully loaded the model 61\n",
      "Fid 68.99867525704182 calculado para 61\n",
      "Arquivo existe:  True\n",
      "Successfully loaded the model 71\n",
      "Fid 68.07579036379151 calculado para 71\n",
      "Arquivo existe:  True\n",
      "Successfully loaded the model 81\n",
      "Fid 70.13721350532902 calculado para 81\n",
      "Arquivo existe:  True\n",
      "Successfully loaded the model 91\n",
      "Fid 69.37113404884661 calculado para 91\n",
      "Arquivo existe:  True\n",
      "There is no checkpoint to load\n",
      "Fid 69.37114365785843 calculado para 101\n"
     ]
    }
   ],
   "source": [
    "import os.path\n",
    "import gc\n",
    "\n",
    "fids = []\n",
    "\n",
    "for i in np.arange(21, 111, 10):\n",
    "  gc.collect()\n",
    "  checkpoint_path = \"/content/drive/Shared drives/Equipe Rocket/8_Sem/Aplic AM/checkpoints/\" + str(i) + \"-120split_trainig.h5\" \n",
    "  print('Arquivo existe: ', os.path.exists(checkpoint_path))\n",
    "\n",
    "  try:\n",
    "      cycle_gan_model.built = True\n",
    "      cycle_gan_model.load_weights(filepath=checkpoint_path)\n",
    "      print(\"Successfully loaded the model \" + str(i))\n",
    "\n",
    "  except:\n",
    "      print(\"There is no checkpoint to load\")\n",
    "\n",
    "  pred = []  \n",
    "  for img in photo_ds:\n",
    "    img_pred = generator_g(img, training = False)[0].numpy()\n",
    "    img_pred = (img_pred * 127.5 + 127.5).astype(np.float32)\n",
    "    pred.append(img_pred)\n",
    "\n",
    "  monet_gen = np.array([img for img in pred])\n",
    "  monet_gen = preprocess_input(monet_gen)\n",
    "  fid_i = calculate_fid_precalculated_stats(model_inception, mu_real, cov_real, monet_gen)\n",
    "\n",
    "  fids.append([i, fid_i])\n",
    "  print(\"Fid \" + str(fid_i) + \" calculado para \" + str(i))\n",
    "\n",
    "  del pred\n",
    "  del monet_gen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "HwvPMTEn8YWM",
    "outputId": "edd0aec1-eb11-49ab-d17f-5b648a1e6a28"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Arquivo existe:  True\n",
      "Successfully loaded the model\n",
      "[[21, 77.10029908511594], [31, 72.2697242132921], [41, 73.18617094437968], [51, 72.41483427190339], [61, 68.99867525704182], [71, 68.07579036379151], [81, 70.13721350532902], [91, 69.37113404884661], [101, 69.37114365785843], [120, 68.75711282309082]]\n"
     ]
    }
   ],
   "source": [
    "checkpoint_path = \"/content/drive/Shared drives/Equipe Rocket/8_Sem/Aplic AM/checkpoints/120split_trainig.h5\" \n",
    "print('Arquivo existe: ', os.path.exists(checkpoint_path))\n",
    "\n",
    "try:\n",
    "  cycle_gan_model.built = True\n",
    "  cycle_gan_model.load_weights(filepath=checkpoint_path)\n",
    "  print(\"Successfully loaded the model\")\n",
    "\n",
    "except:\n",
    "  print(\"There is no checkpoint to load\")\n",
    "\n",
    "pred = []  \n",
    "for img in photo_ds:\n",
    "  img_pred = generator_g(img, training = False)[0].numpy()\n",
    "  img_pred = (img_pred * 127.5 + 127.5).astype(np.float32)\n",
    "  pred.append(img_pred)\n",
    "\n",
    "monet_gen = np.array([img for img in pred])\n",
    "monet_gen = preprocess_input(monet_gen)\n",
    "fid_i = calculate_fid_precalculated_stats(model_inception, mu_real, cov_real, monet_gen)\n",
    "\n",
    "fids.append([120, fid_i])\n",
    "\n",
    "print(fids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 542
    },
    "id": "Pwmi0B5u85lP",
    "outputId": "1fcc9854-db4d-459a-d05c-8ef95815f0a2"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<html>\n",
       "<head><meta charset=\"utf-8\" /></head>\n",
       "<body>\n",
       "    <div>\n",
       "            <script src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_SVG\"></script><script type=\"text/javascript\">if (window.MathJax) {MathJax.Hub.Config({SVG: {font: \"STIX-Web\"}});}</script>\n",
       "                <script type=\"text/javascript\">window.PlotlyConfig = {MathJaxConfig: 'local'};</script>\n",
       "        <script src=\"https://cdn.plot.ly/plotly-latest.min.js\"></script>    \n",
       "            <div id=\"d169ccf6-253a-4fe3-be30-f997f883cc0e\" class=\"plotly-graph-div\" style=\"height:525px; width:100%;\"></div>\n",
       "            <script type=\"text/javascript\">\n",
       "                \n",
       "                    window.PLOTLYENV=window.PLOTLYENV || {};\n",
       "                    \n",
       "                if (document.getElementById(\"d169ccf6-253a-4fe3-be30-f997f883cc0e\")) {\n",
       "                    Plotly.newPlot(\n",
       "                        'd169ccf6-253a-4fe3-be30-f997f883cc0e',\n",
       "                        [{\"mode\": \"lines+markers\", \"type\": \"scatter\", \"x\": [21, 31, 41, 51, 61, 71, 81, 91, 101, 120], \"y\": [77.10029908511594, 72.2697242132921, 73.18617094437968, 72.41483427190339, 68.99867525704182, 68.07579036379151, 70.13721350532902, 69.37113404884661, 69.37114365785843, 68.75711282309082]}],\n",
       "                        {\"template\": {\"data\": {\"bar\": [{\"error_x\": {\"color\": \"#2a3f5f\"}, \"error_y\": {\"color\": \"#2a3f5f\"}, \"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"bar\"}], \"barpolar\": [{\"marker\": {\"line\": {\"color\": \"#E5ECF6\", \"width\": 0.5}}, \"type\": \"barpolar\"}], \"carpet\": [{\"aaxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"baxis\": {\"endlinecolor\": \"#2a3f5f\", \"gridcolor\": \"white\", \"linecolor\": \"white\", \"minorgridcolor\": \"white\", \"startlinecolor\": \"#2a3f5f\"}, \"type\": \"carpet\"}], \"choropleth\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"choropleth\"}], \"contour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"contour\"}], \"contourcarpet\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"contourcarpet\"}], \"heatmap\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmap\"}], \"heatmapgl\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"heatmapgl\"}], \"histogram\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"histogram\"}], \"histogram2d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2d\"}], \"histogram2dcontour\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"histogram2dcontour\"}], \"mesh3d\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"type\": \"mesh3d\"}], \"parcoords\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"parcoords\"}], \"pie\": [{\"automargin\": true, \"type\": \"pie\"}], \"scatter\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter\"}], \"scatter3d\": [{\"line\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatter3d\"}], \"scattercarpet\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattercarpet\"}], \"scattergeo\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergeo\"}], \"scattergl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattergl\"}], \"scattermapbox\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scattermapbox\"}], \"scatterpolar\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolar\"}], \"scatterpolargl\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterpolargl\"}], \"scatterternary\": [{\"marker\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"type\": \"scatterternary\"}], \"surface\": [{\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}, \"colorscale\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"type\": \"surface\"}], \"table\": [{\"cells\": {\"fill\": {\"color\": \"#EBF0F8\"}, \"line\": {\"color\": \"white\"}}, \"header\": {\"fill\": {\"color\": \"#C8D4E3\"}, \"line\": {\"color\": \"white\"}}, \"type\": \"table\"}]}, \"layout\": {\"annotationdefaults\": {\"arrowcolor\": \"#2a3f5f\", \"arrowhead\": 0, \"arrowwidth\": 1}, \"coloraxis\": {\"colorbar\": {\"outlinewidth\": 0, \"ticks\": \"\"}}, \"colorscale\": {\"diverging\": [[0, \"#8e0152\"], [0.1, \"#c51b7d\"], [0.2, \"#de77ae\"], [0.3, \"#f1b6da\"], [0.4, \"#fde0ef\"], [0.5, \"#f7f7f7\"], [0.6, \"#e6f5d0\"], [0.7, \"#b8e186\"], [0.8, \"#7fbc41\"], [0.9, \"#4d9221\"], [1, \"#276419\"]], \"sequential\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]], \"sequentialminus\": [[0.0, \"#0d0887\"], [0.1111111111111111, \"#46039f\"], [0.2222222222222222, \"#7201a8\"], [0.3333333333333333, \"#9c179e\"], [0.4444444444444444, \"#bd3786\"], [0.5555555555555556, \"#d8576b\"], [0.6666666666666666, \"#ed7953\"], [0.7777777777777778, \"#fb9f3a\"], [0.8888888888888888, \"#fdca26\"], [1.0, \"#f0f921\"]]}, \"colorway\": [\"#636efa\", \"#EF553B\", \"#00cc96\", \"#ab63fa\", \"#FFA15A\", \"#19d3f3\", \"#FF6692\", \"#B6E880\", \"#FF97FF\", \"#FECB52\"], \"font\": {\"color\": \"#2a3f5f\"}, \"geo\": {\"bgcolor\": \"white\", \"lakecolor\": \"white\", \"landcolor\": \"#E5ECF6\", \"showlakes\": true, \"showland\": true, \"subunitcolor\": \"white\"}, \"hoverlabel\": {\"align\": \"left\"}, \"hovermode\": \"closest\", \"mapbox\": {\"style\": \"light\"}, \"paper_bgcolor\": \"white\", \"plot_bgcolor\": \"#E5ECF6\", \"polar\": {\"angularaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"radialaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"scene\": {\"xaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"yaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}, \"zaxis\": {\"backgroundcolor\": \"#E5ECF6\", \"gridcolor\": \"white\", \"gridwidth\": 2, \"linecolor\": \"white\", \"showbackground\": true, \"ticks\": \"\", \"zerolinecolor\": \"white\"}}, \"shapedefaults\": {\"line\": {\"color\": \"#2a3f5f\"}}, \"ternary\": {\"aaxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"baxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}, \"bgcolor\": \"#E5ECF6\", \"caxis\": {\"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\"}}, \"title\": {\"x\": 0.05}, \"xaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}, \"yaxis\": {\"automargin\": true, \"gridcolor\": \"white\", \"linecolor\": \"white\", \"ticks\": \"\", \"title\": {\"standoff\": 15}, \"zerolinecolor\": \"white\", \"zerolinewidth\": 2}}}, \"title\": {\"text\": \"Evolu\\u00e7\\u00e3o do FID ao longo da fase de treinamento\"}, \"xaxis\": {\"title\": {\"text\": \"\\u00c9pocas\"}}, \"yaxis\": {\"title\": {\"text\": \"Valor de FID\"}}},\n",
       "                        {\"responsive\": true}\n",
       "                    ).then(function(){\n",
       "                            \n",
       "var gd = document.getElementById('d169ccf6-253a-4fe3-be30-f997f883cc0e');\n",
       "var x = new MutationObserver(function (mutations, observer) {{\n",
       "        var display = window.getComputedStyle(gd).display;\n",
       "        if (!display || display === 'none') {{\n",
       "            console.log([gd, 'removed!']);\n",
       "            Plotly.purge(gd);\n",
       "            observer.disconnect();\n",
       "        }}\n",
       "}});\n",
       "\n",
       "// Listen for the removal of the full notebook cells\n",
       "var notebookContainer = gd.closest('#notebook-container');\n",
       "if (notebookContainer) {{\n",
       "    x.observe(notebookContainer, {childList: true});\n",
       "}}\n",
       "\n",
       "// Listen for the clearing of the current output cell\n",
       "var outputEl = gd.closest('.output');\n",
       "if (outputEl) {{\n",
       "    x.observe(outputEl, {childList: true});\n",
       "}}\n",
       "\n",
       "                        })\n",
       "                };\n",
       "                \n",
       "            </script>\n",
       "        </div>\n",
       "</body>\n",
       "</html>"
      ]
     },
     "metadata": {
      "tags": []
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import plotly.graph_objects as go\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "fids_x = []\n",
    "fids_y = []\n",
    "\n",
    "for i in range(10):\n",
    "  fids_x.append(fids[i][0])\n",
    "  fids_y.append(fids[i][1])\n",
    "\n",
    "\n",
    "layout = dict(xaxis=dict(title = \"Epochs\"))\n",
    "fig = go.Figure(go.Scatter(x=fids_x, y=fids_y, mode='lines+markers'))\n",
    "fig.update_layout(title = \"Evolução do FID ao longo da fase de treinamento\", xaxis_title=\"Épocas\" , yaxis_title=\"Valor de FID\")#, layout = layout)\n",
    "fig.show()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "name": "CalcFid.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
